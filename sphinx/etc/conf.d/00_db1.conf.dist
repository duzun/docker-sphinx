#
# Sphinx configuration file sample
#
# WARNING! While this sample file mentions all available options,
# it contains (very) short helper descriptions only. Please refer to
# doc/sphinx.html for details.
#

#############################################################################
## data source definition
#############################################################################

source src1: mysql {	
	sql_db = $DB # $DB variable is "db1" from filename or defined by $DATABASE_DB1 env variable when present

	# main document fetch query
	# mandatory, integer document ID field MUST be the first selected column
	sql_query		= \
		SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, title, content \
		FROM documents

	# joined/payload field fetch query
	# joined fields let you avoid (slow) JOIN and GROUP_CONCAT
	# payload fields let you attach custom per-keyword values (eg. for ranking)
	#
	# syntax is FIELD-NAME 'from'  ( 'query' | 'payload-query' ); QUERY
	# joined field QUERY should return 2 columns (docid, text)
	# payload field QUERY should return 3 columns (docid, keyword, weight)
	#
	# REQUIRES that query results are in ascending document ID order!
	# multi-value, optional, default is empty list of queries
	#
	# sql_joined_field	= tags from query; SELECT docid, CONCAT('tag',tagid) FROM tags ORDER BY docid ASC
	# sql_joined_field	= wtags from payload-query; SELECT docid, tag, tagweight FROM tags ORDER BY docid ASC


	# file based field declaration
	#
	# content of this field is treated as a file name
	# and the file gets loaded and indexed in place of a field
	#
	# max file size is limited by max_file_field_buffer indexer setting
	# file IO errors are non-fatal and get reported as warnings
	#
	# sql_file_field		= content_file_path


	# range query setup, query that must return min and max ID values
	# optional, default is empty
	#
	# sql_query will need to reference $start and $end boundaries
	# if using ranged query:
	#
	# sql_query		= \
	#	SELECT doc.id, doc.id AS group, doc.title, doc.data \
	#	FROM documents doc \
	#	WHERE id>=$start AND id<=$end
	#
	# sql_query_range		= SELECT MIN(id),MAX(id) FROM documents


	# range query step
	# optional, default is 1024
	#
	# sql_range_step		= 1000


	# unsigned integer attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# optional bit size can be specified, default is 32
	#
	# sql_attr_uint		= author_id
	# sql_attr_uint		= forum_id:9 # 9 bits for forum_id
	sql_attr_uint		= group_id

	# boolean attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# equivalent to sql_attr_uint with 1-bit size
	#
	# sql_attr_bool		= is_deleted


	# bigint attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# declares a signed (unlike uint!) 64-bit attribute
	#
	# sql_attr_bigint		= my_bigint_id


	# UNIX timestamp attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# similar to integer, but can also be used in date functions
	#
	# sql_attr_timestamp	= posted_ts
	# sql_attr_timestamp	= last_edited_ts
	sql_attr_timestamp	= date_added


	# floating point attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# values are stored in single precision, 32-bit IEEE 754 format
	#
	# sql_attr_float		= lat_radians
	# sql_attr_float		= long_radians


	# multi-valued attribute (MVA) attribute declaration
	# multi-value (an arbitrary number of attributes is allowed), optional
	# MVA values are variable length lists of unsigned 32-bit integers
	#
	# syntax is ATTR-TYPE ATTR-NAME 'from' SOURCE-TYPE [;QUERY] [;RANGE-QUERY]
	# ATTR-TYPE is 'uint' or 'timestamp'
	# SOURCE-TYPE is 'field', 'query', or 'ranged-query'
	# QUERY is SQL query used to fetch all ( docid, attrvalue ) pairs
	# RANGE-QUERY is SQL query used to fetch min and max ID values, similar to 'sql_query_range'
	#
	# sql_attr_multi		= uint tag from query; SELECT docid, tagid FROM tags
	# sql_attr_multi		= uint tag from ranged-query; \
	#	SELECT docid, tagid FROM tags WHERE id>=$start AND id<=$end; \
	#	SELECT MIN(docid), MAX(docid) FROM tags


	# string attribute declaration
	# multi-value (an arbitrary number of these is allowed), optional
	# lets you store and retrieve strings
	#
	# sql_attr_string		= stitle


	# JSON attribute declaration
	# multi-value (an arbitrary number of these is allowed), optional
	# lets you store a JSON document as an (in-memory) attribute for later use
	#
	# sql_attr_json		= properties


	# combined field plus attribute declaration (from a single column)
	# stores column as an attribute, but also indexes it as a full-text field
	#
	# sql_field_string	= author

	
	# post-query, executed on sql_query completion
	# optional, default is empty
	#
	# sql_query_post		=

	
	# post-index-query, executed on successful indexing completion
	# optional, default is empty
	# $maxid expands to max document ID actually fetched from DB
	#
	# sql_query_post_index	= REPLACE INTO counters ( id, val ) \
	#	VALUES ( 'max_indexed_id', $maxid )


	# kill-list query, fetches the document IDs for kill-list
	# k-list will suppress matches from preceding indexes in the same query
	# optional, default is empty
	#
	# sql_query_killlist	= SELECT id FROM documents WHERE edited>=@last_reindex


	# hook command to run when SQL connection succeeds
	# optional, default value is empty (do nothing)
	#
	# hook_connect			= bash sql_connect.sh


	# hook command to run after (any) SQL range query
	# it may print out "minid maxid" (w/o quotes) to override the range
	# optional, default value is empty (do nothing)
	#
	# hook_query_range		= bash sql_query_range.sh


	# hook command to run on successful indexing completion
	# $maxid expands to max document ID actually fetched from DB
	# optional, default value is empty (do nothing)
	#
	# hook_post_index		= bash sql_post_index.sh $maxid

	#####################################################################
	## xmlpipe2 settings
	#####################################################################

	# type			= xmlpipe

	# shell command to invoke xmlpipe stream producer
	# mandatory
	#
	# xmlpipe_command		= cat /var/lib/sphinx/test.xml

	# xmlpipe2 field declaration
	# multi-value, optional, default is empty
	#
	# xmlpipe_field		= subject
	# xmlpipe_field		= content


	# xmlpipe2 attribute declaration
	# multi-value, optional, default is empty
	# all xmlpipe_attr_XXX options are fully similar to sql_attr_XXX
	# examples:
	#
	# xmlpipe_attr_timestamp	= published
	# xmlpipe_attr_uint	= author_id
	# xmlpipe_attr_bool	= is_enabled
	# xmlpipe_attr_float	= latitude
	# xmlpipe_attr_bigint	= guid
	# xmlpipe_attr_multi	= tags
	# xmlpipe_attr_multi_64	= tags64
	# xmlpipe_attr_string	= title
	# xmlpipe_attr_json	= extra_data
	# xmlpipe_field_string	= content


	# perform UTF-8 validation, and filter out incorrect codes
	# avoids XML parser choking on non-UTF-8 documents
	# optional, default is 0
	#
	# xmlpipe_fixup_utf8	= 1
}


#############################################################################
## index definition
#############################################################################

# local index example
#
# this is an index which is stored locally in the filesystem
#
# all indexing-time options (such as morphology and charsets)
# are configured per local index
index test1 {
	# index type
	# optional, default is 'plain'
	# known values are 'plain', 'distributed', and 'rt' (see samples below)
	# type			= plain

	# document source(s) to index
	# multi-value, mandatory
	# document IDs must be globally unique across all sources
	source			= src1

	# index files path and file name, without extension
	# mandatory, path must be writable, extensions will be auto-appended
	path			= $SPHINX_DATA_PATH/test1

	# document attribute values (docinfo) storage mode
	# optional, default is 'extern'
	# known values are 'none', 'extern' and 'inline'
	docinfo			= extern

	# dictionary type, 'crc' or 'keywords'
	# crc is faster to index when no substring/wildcards searches are needed
	# crc with substrings might be faster to search but is much slower to index
	# (because all substrings are pre-extracted as individual keywords)
	# keywords is much faster to index with substrings, and index is much (3-10x) smaller
	# keywords supports wildcards, crc does not, and never will
	# optional, default is 'keywords'
	dict			= keywords

	# memory locking for cached data (.spa and .spi), to prevent swapping
	# optional, default is 0 (do not mlock)
	# requires searchd to be run from root
	mlock			= 0

	# a list of morphology preprocessors to apply
	# optional, default is empty
	#
	# builtin preprocessors are 'none', 'stem_en', 'stem_ru', 'stem_enru',
	# 'soundex', and 'metaphone'; additional preprocessors available from
	# libstemmer are 'libstemmer_XXX', where XXX is algorithm code
	# (see libstemmer_c/libstemmer/modules.txt)
	#
	# morphology		= stem_en, stem_ru, soundex
	# morphology		= libstemmer_german
	# morphology		= libstemmer_sv
	morphology		= none

	# minimum word length at which to enable stemming
	# optional, default is 1 (stem everything)
	#
	# min_stemming_len	= 1


	# stopword files list (space separated)
	# optional, default is empty
	# contents are plain text, charset_table and stemming are both applied
	#
	# stopwords		= $SPHINX_DATA_PATH/stopwords.txt


	# wordforms file, in "mapfrom > mapto" plain text format
	# optional, default is empty
	#
	# wordforms		= $SPHINX_DATA_PATH/wordforms.txt


	# tokenizing exceptions file
	# optional, default is empty
	#
	# plain text, case sensitive, space insensitive in map-from part
	# one "Map Several Words => ToASingleOne" entry per line
	#
	# exceptions		= $SPHINX_DATA_PATH/exceptions.txt


	# embedded file size limit
	# optional, default is 16K
	#
	# exceptions, wordforms, and stopwords files smaller than this limit
	# are stored in the index; otherwise, their paths and sizes are stored
	#
	# embedded_limit		= 16K

	# minimum indexed word length
	# default is 1 (index everything)
	min_word_len		= 1


	# ignored characters list
	# optional, default value is empty
	#
	# ignore_chars		= U+00AD


	# minimum word prefix length to index
	# optional, default is 0 (do not index prefixes)
	#
	# min_prefix_len		= 0


	# minimum word infix length to index
	# optional, default is 0 (do not index infixes)
	#
	# min_infix_len		= 0


	# maximum substring (prefix or infix) length to index
	# optional, default is 0 (do not limit substring length)
	#
	# max_substring_len	= 8


	# list of fields to limit prefix/infix indexing to
	# optional, default value is empty (index all fields in prefix/infix mode)
	#
	# prefix_fields		= filename
	# infix_fields		= url, domain


	# expand keywords with exact forms and/or stars when searching fit indexes
	# search-time only, does not affect indexing, can be 0 or 1
	# optional, default is 0 (do not expand keywords)
	#
	# expand_keywords		= 1

	
	# n-gram length to index, for CJK indexing
	# only supports 0 and 1 for now, other lengths to be implemented
	# optional, default is 0 (disable n-grams)
	#
	# ngram_len		= 1


	# n-gram characters list, for CJK indexing
	# optional, default is empty
	#
	# ngram_chars		= U+3000..U+2FA1F


	# phrase boundary characters list
	# optional, default is empty
	#
	# phrase_boundary		= ., ?, !, U+2026 # horizontal ellipsis


	# phrase boundary word position increment
	# optional, default is 0
	#
	# phrase_boundary_step	= 100


	# blended characters list
	# blended chars are indexed both as separators and valid characters
	# for instance, AT&T will results in 3 tokens ("at", "t", and "at&t")
	# optional, default is empty
	#
	# blend_chars		= +, &, U+23


	# blended token indexing mode
	# a comma separated list of blended token indexing variants
	# known variants are trim_none, trim_head, trim_tail, trim_both, skip_pure
	# optional, default is trim_none
	#
	# blend_mode		= trim_tail, skip_pure


	# whether to strip HTML tags from incoming documents
	# known values are 0 (do not strip) and 1 (do strip)
	# optional, default is 0
	html_strip		= 0

	# what HTML attributes to index if stripping HTML
	# optional, default is empty (do not index anything)
	#
	# html_index_attrs	= img=alt,title; a=title;


	# what HTML elements contents to strip
	# optional, default is empty (do not strip element contents)
	#
	# html_remove_elements	= style, script


	# whether to preopen index data files on startup
	# optional, default is 0 (do not preopen), searchd-only
	#
	# preopen			= 1


	# whether to enable in-place inversion (2x less disk, 90-95% speed)
	# optional, default is 0 (use separate temporary files), indexer-only
	#
	# inplace_enable		= 1


	# in-place fine-tuning options
	# optional, defaults are listed below
	#
	# inplace_hit_gap		= 0 # preallocated hitlist gap size
	# inplace_docinfo_gap	= 0 # preallocated docinfo gap size
	# inplace_reloc_factor	= 0.1 # relocation buffer size within arena
	# inplace_write_factor	= 0.1 # write buffer size within arena


	# whether to index original keywords along with stemmed versions
	# enables "=exactform" operator to work
	# optional, default is 0
	#
	# index_exact_words	= 1


	# position increment on overshort (less that min_word_len) words
	# optional, allowed values are 0 and 1, default is 1
	#
	# overshort_step		= 1


	# position increment on stopword
	# optional, allowed values are 0 and 1, default is 1
	#
	# stopword_step		= 1


	# hitless words list
	# positions for these keywords will not be stored in the index
	# optional, allowed values are 'all', or a list file name
	#
	# hitless_words		= all
	# hitless_words		= hitless.txt


	# detect and index sentence and paragraph boundaries
	# required for the SENTENCE and PARAGRAPH operators to work
	# optional, allowed values are 0 and 1, default is 0
	#
	# index_sp			= 1


	# index zones, delimited by HTML/XML tags
	# a comma separated list of tags and wildcards
	# required for the ZONE operator to work
	# optional, default is empty string (do not index zones)
	#
	# index_zones		= title, h*, th


	# index per-document and average per-index field lengths, in tokens
	# required for the BM25A(), BM25F() in expression ranker
	# optional, default is 0 (do not index field lenghts)
	#
	# index_field_lengths	= 1


	# regular expressions (regexps) to filter the fields and queries with
	# gets applied to data source fields when indexing
	# gets applied to search queries when searching
	# multi-value, optional, default is empty list of regexps
	#
	# regexp_filter		= \b(\d+)\" => \1inch
	# regexp_filter		= (blue|red) => color


	# list of the words considered frequent with respect to bigram indexing
	# optional, default is empty
	#
	# bigram_freq_words	= the, a, i, you, my


	# bigram indexing mode
	# known values are none, all, first_freq, both_freq
	# option, default is none (do not index bigrams)
	#
	# bigram_index		= both_freq


	# snippet document file name prefix
	# preprended to file names when generating snippets using load_files option
	# WARNING, this is a prefix (not a path), trailing slash matters!
	# optional, default is empty
	#
	# snippets_file_prefix	= /mnt/mydocs/server1


	# whether to apply stopwords before or after stemming
	# optional, default is 0 (apply stopwords after stemming)
	#
	# stopwords_unstemmed	= 0


	# path to a global (cluster-wide) keyword IDFs file
	# optional, default is empty (use local IDFs)
	#
	# global_idf		= /usr/local/sphinx/var/global.idf
}


# inherited index example
#
# all the parameters are copied from the parent index,
# and may then be overridden in this index definition
index test1stemmed : test1 {
	path			= $SPHINX_DATA_PATH/test1stemmed
	morphology		= stem_en
}


# distributed index example
#
# this is a virtual index which can NOT be directly indexed,
# and only contains references to other local and/or remote indexes
index dist1 {
	# 'distributed' index type MUST be specified
	type			= distributed

	# local index to be searched
	# there can be many local indexes configured
	local			= test1
	local			= test1stemmed

	# remote agent
	# multiple remote agents may be specified
	# syntax for TCP connections is 'hostname:port:index1,[index2[,...]]'
	# syntax for local UNIX connections is '/path/to/socket:index1,[index2[,...]]'
	agent			= localhost:9313:remote1
	agent			= localhost:9314:remote2,remote3
	# agent			= /var/run/searchd.sock:remote4

	# remote agent mirrors groups, aka mirrors, aka HA agents
	# defines 2 or more interchangeable mirrors for a given index part
	#
	# agent			= server3:9312 | server4:9312 :indexchunk2
	# agent			= server3:9312:chunk2server3 | server4:9312:chunk2server4
	# agent			= server3:chunk2server3 | server4:chunk2server4
	# agent			= server21|server22|server23:chunk2


	# blackhole remote agent, for debugging/testing
	# network errors and search results will be ignored
	#
	# agent_blackhole		= testbox:9312:testindex1,testindex2


	# persistenly connected remote agent
	# reduces connect() pressure, requires that workers IS threads
	#
	# agent_persistent		= testbox:9312:testindex1,testindex2


	# remote agent connection timeout, milliseconds
	# optional, default is 1000 ms, ie. 1 sec
	agent_connect_timeout	= 1000

	# remote agent query timeout, milliseconds
	# optional, default is 3000 ms, ie. 3 sec
	agent_query_timeout		= 3000

	# HA mirror agent strategy
	# optional, defaults to ??? (random mirror)
	# know values are nodeads, noerrors, roundrobin, nodeadstm, noerrorstm
	#
	# ha_strategy				= nodeads

	# path to RLP context file
	# optional, defaut is empty
	#
	# rlp_context = /usr/local/share/sphinx/rlp/rlp-context.xml
}
